{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Test Datasets From Source\n",
    "\n",
    "### Append (Stack)\n",
    "\n",
    "> Pass (no variance in in/out params) - no lengthening\n",
    "\n",
    "> Pass (no variance in in/out params) - with lengthening\n",
    "\n",
    "> Pass with warning (new columns)\n",
    "\n",
    "> Pass with warning (cast child dataset to parent datatype)\n",
    "\n",
    "> Fail (cast of child fails to meet parent specification)\n",
    "\n",
    "\n",
    "### Merge (History Preserving)\n",
    "\n",
    "> Pass (no variance in in/out params) - no lengthening\n",
    "\n",
    "> Pass (no variance in in/out params) - with lengthening\n",
    "\n",
    "> Pass with warning (new columns)\n",
    "\n",
    "> Pass with warning (cast child dataset to parent datatype)\n",
    "\n",
    "> Fail (cast of child fails to meet parent specification)\n",
    "\n",
    "\n",
    "### Replace\n",
    "\n",
    "> Pass (Output == Child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_CRS_SBJ</th>\n",
       "      <th>C_TITLE</th>\n",
       "      <th>C_CRS_UNIQUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANTH</td>\n",
       "      <td>PERSPECTIVES ON RACE (DSS)(CI)</td>\n",
       "      <td>ANTH3200TO1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEM</td>\n",
       "      <td>GENERAL CHEMISTRY I (BPS)</td>\n",
       "      <td>CHEM1110KB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COMD</td>\n",
       "      <td>ETHICS/CRTCL THNK INTERPRETERS</td>\n",
       "      <td>COMD5920LO1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECN</td>\n",
       "      <td>APPLIED ECONOMETRICS (QI)</td>\n",
       "      <td>ECN4330AO1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENVS</td>\n",
       "      <td>HUMAN DIM WILDLIFE MGMT</td>\n",
       "      <td>ENVS4110NO1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  C_CRS_SBJ                         C_TITLE C_CRS_UNIQUE\n",
       "0      ANTH  PERSPECTIVES ON RACE (DSS)(CI)  ANTH3200TO1\n",
       "1      CHEM       GENERAL CHEMISTRY I (BPS)  CHEM1110KB1\n",
       "2      COMD  ETHICS/CRTCL THNK INTERPRETERS  COMD5920LO1\n",
       "3       ECN       APPLIED ECONOMETRICS (QI)   ECN4330AO1\n",
       "4      ENVS         HUMAN DIM WILDLIFE MGMT  ENVS4110NO1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = pd.read_csv('source_complete.csv', encoding='latin-1')\n",
    "source.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Class\n",
    "\n",
    "This is a bundle container for holding multiple transforms needed for making each pass, fail, case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from case import Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'empty'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Case(source=source)\n",
    "c.report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers\n",
    "\n",
    "These do the heavy lifting, taking in data, making changes, and returning necessary outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'empty'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Transformer(name='test')\n",
    "t.transform(source)\n",
    "t.report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GOAl UI\n",
    "## How should the user interact with the transformers?\n",
    "\n",
    "# case.split(n=, size=[float])  # Split dataset into parts\n",
    "# case.add_col(n=, column=, specs={DATAGEN})  # Add column of given specificatuion to dataset\n",
    "# case.remove_col(n=, column=, index=)  # Remove column from dataset\n",
    "# case.change_type(n=, column=, index=)  # Change datatype of column in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split\n",
    "\n",
    "Split data into n components of specified size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitTransform(Transformer):\n",
    "    def __init__(self, n=2, size=None, data: pd.DataFrame = None):\n",
    "        super().__init__(name='split')\n",
    "        self.transform(data, n, size)\n",
    "    \n",
    "    def transform(self, data, n, size):\n",
    "        assert type(data) == pd.DataFrame\n",
    "        if size is not None:\n",
    "            assert sum(size) == 1, 'Split fractions must sum to 1.0'\n",
    "            assert len(size) == n, 'Must provide fractions for all splits'\n",
    "        # Get data length\n",
    "        dlen = len(data)\n",
    "        # Define breakpoints\n",
    "        if size is None:\n",
    "            size = [1/n for _ in range(n)]\n",
    "        \n",
    "        breakpoints = []\n",
    "        for count, fraction in enumerate(size):\n",
    "            if count == 0:\n",
    "                point = fraction * dlen\n",
    "            else:\n",
    "                point = fraction * dlen + breakpoints[count - 1]\n",
    "            \n",
    "            breakpoints.append(int(point))\n",
    "        \n",
    "        # Fix breakpoints :(\\)\n",
    "        breakpoints.insert(0, 0)\n",
    "        breakpoints.pop()\n",
    "            \n",
    "        print('Breakpoints: ', breakpoints)\n",
    "            \n",
    "        # Bin dataframe at breakpoints\n",
    "        new_data = {}\n",
    "        for index in range(len(breakpoints)):\n",
    "            if index < len(breakpoints) - 1:\n",
    "                print('{}:{}'.format(breakpoints[index], breakpoints[index+1]))\n",
    "                temp = data.iloc[breakpoints[index]:breakpoints[index+1]]\n",
    "            else:\n",
    "                temp = data.iloc[breakpoints[index]:dlen]\n",
    "                      \n",
    "            new_data[index] = temp\n",
    "        \n",
    "        \n",
    "        # Create report components\n",
    "        self.input_shape = data.shape\n",
    "        self.output_shape = {key: new_data[key].shape for key in new_data}\n",
    "        message = f'Data successfully split into {len(new_data)} pieces'\n",
    "        \n",
    "        print(len(new_data))\n",
    "        \n",
    "        super().transform(data=new_data, message=message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoints:  [0, 26908, 80724, 96868]\n",
      "0:26908\n",
      "26908:80724\n",
      "80724:96868\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Transformer': 'split',\n",
       " 'input_shape': (107633, 3),\n",
       " 'output_shape': {0: (26908, 3), 1: (53816, 3), 2: (16144, 3), 3: (10765, 3)},\n",
       " 'message': 'Data successfully split into 4 pieces'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = SplitTransform(n=4, size=[0.25, 0.5, 0.15, 0.1], data=source.copy())\n",
    "st.report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107633"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
